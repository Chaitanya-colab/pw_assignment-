{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Generate a list of 100 integers containing values between 90 to 130 and store it in the variable int_list. After generating the list, find the following**"
      ],
      "metadata": {
        "id": "W69fnVjWpUog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [random.randint(90, 130) for _ in range(100)]"
      ],
      "metadata": {
        "id": "wQreXK_r0MWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Write a Python function to calculate the mean of a given list of numbers. Create a function to find the median of a list of numbers."
      ],
      "metadata": {
        "id": "tD9jLKWaoaFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean(data):\n",
        "    return sum(data) / len(data)\n",
        "\n",
        "def calculate_median(data):\n",
        "    sorted_numbers = sorted(data)\n",
        "    n = len(sorted_numbers)\n",
        "    if n % 2 == 1:\n",
        "        return sorted_numbers[n // 2]\n",
        "    else:\n",
        "        return (sorted_numbers[n // 2 - 1] + sorted_numbers[n // 2]) / 2\n",
        "calculate_median(data)"
      ],
      "metadata": {
        "id": "iNK26FwCwJTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Develop a program to compute the mode of a list of integers."
      ],
      "metadata": {
        "id": "J4RHk4V0ofRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mode(data):\n",
        "  counts = {}\n",
        "  for num in data:\n",
        "    counts[num] = counts.get(num, 0) + 1\n",
        "  max_count = max(counts.values())\n",
        "  return [num for num, count in counts.items() if count == max_count]\n",
        "\n",
        "print(mode(data))"
      ],
      "metadata": {
        "id": "TuYpyjnFxI0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iii) Implement a function to calculate the weighted mean of a list of values and their corresponding weights."
      ],
      "metadata": {
        "id": "ic3N4RV3ofOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_mean(data, weights):\n",
        "\n",
        "  if len(data) != len(weights):\n",
        "    return \"Data and weights lists must have the same length\"\n",
        "\n",
        "  numerator = sum(value * weight for value, weight in zip(data, weights))\n",
        "  denominator = sum(weights)\n",
        "  return numerator / denominator\n",
        "\n",
        "data1 = [1,2, 3, 4, 5]\n",
        "weights = [1, 2, 3, 4, 5]\n",
        "weighted_mean(data1, weights)"
      ],
      "metadata": {
        "id": "1ZzFoTUIxYM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iv) Write a Python function to find the geometric mean of a list of positive numbers."
      ],
      "metadata": {
        "id": "G_9zxURDofMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def geometric_mean(data):\n",
        "\n",
        "  if any(value <= 0 for value in data):\n",
        "    return \"Geometric mean requires all positive numbers\"\n",
        "  product = 1\n",
        "  for num in data:\n",
        "    product *= num\n",
        "  return product**(1/len(data))\n",
        "\n",
        "geometric_mean(data)"
      ],
      "metadata": {
        "id": "4u7C_LGqx_gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(v) Create a program to calculate the harmonic mean of a list of values."
      ],
      "metadata": {
        "id": "sYUsGAIYofJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def harmonic_mean(data):\n",
        "  if any(value <= 0 for value in data):\n",
        "    return \"Harmonic mean requires all positive numbers\"\n",
        "  return len(data) / sum(1 / value for value in data)\n",
        "\n",
        "harmonic_mean(data)"
      ],
      "metadata": {
        "id": "KcLPJ4dczHcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(vi) Build a function to determine the midrange of a list of numbers (average of the minimum and maximum)."
      ],
      "metadata": {
        "id": "tOjWvXfuofHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def midrange(data):\n",
        "\n",
        "  if not data:\n",
        "    return \"Input list cannot be empty\"\n",
        "  return (min(data) + max(data)) / 2\n",
        "\n",
        "midrange(data)"
      ],
      "metadata": {
        "id": "XWAdKmNizp5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(vii) Implement a Python program to find the trimmed mean of a list, excluding a certain percentage of outliers."
      ],
      "metadata": {
        "id": "uXpWV8TuofEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def trimmed_mean(data, percentage):\n",
        "  if not 0 <= percentage < 1:\n",
        "    return \"Percentage must be between 0 and 1\"\n",
        "  sorted_data = sorted(data)\n",
        "  n = len(sorted_data)\n",
        "  trim_count = int(n * percentage / 2)\n",
        "  trimmed_data = sorted_data[trim_count:n - trim_count]\n",
        "  return np.mean(trimmed_data)\n",
        "\n",
        "percentage = 0.2\n",
        "trimmed_mean(data, percentage)"
      ],
      "metadata": {
        "id": "wqVgCXZazxds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "data1 = [random.randint(200, 300) for _ in range(500)]"
      ],
      "metadata": {
        "id": "jNr2Xter0PqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Generate a list of 500 integers containing values between 200 to 300 and store it in the variable int_list2. After generating the list, find the following:**"
      ],
      "metadata": {
        "id": "bo28pqTOpP84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Compare the given list of visualization for the given data:\n",
        "1. Frequency & Gaussian distribution\n",
        "2. Frequency smoothened KDE plot\n",
        "3. Gaussian distribution & smoothened KDE plot"
      ],
      "metadata": {
        "id": "kEhJSqWZowQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data1, bins=20, kde=False, color='skyblue')\n",
        "plt.title('Frequency Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "mean2 = np.mean(data1)\n",
        "std2 = np.std(data1)\n",
        "\n",
        "x = np.linspace(min(data1), max(data1), 500)\n",
        "gaussian = (1/(std2 * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean2)/std2)**2)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x, gaussian, color='red')\n",
        "plt.title('Gaussian Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.kdeplot(data1, color='blue')\n",
        "plt.title('Frequency Smoothened KDE Plot')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.kdeplot(data1, color='blue', label='KDE')\n",
        "plt.plot(x, gaussian, color='red', label='Gaussian')\n",
        "plt.title('Gaussian Distribution & Smoothened KDE Plot')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5Tn4BpCJ2ltM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Write a Python function to calculate the range of a given list of numbers."
      ],
      "metadata": {
        "id": "nr_-tab3o8HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range(numbers):\n",
        "  if not numbers:\n",
        "    return\"List cannot be empty\"\n",
        "\n",
        "  smallest = min(numbers)\n",
        "  largest = max(numbers)\n",
        "  return largest - smallest\n",
        "\n",
        "calculate_range(data1)"
      ],
      "metadata": {
        "id": "8Hom_2I53QMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iii) Create a program to find the variance and standard deviation of a list of numbers."
      ],
      "metadata": {
        "id": "YzR3bnuFo7-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_variance(numbers):\n",
        "\n",
        "  if not numbers:\n",
        "    raise ValueError(\"List cannot be empty\")\n",
        "\n",
        "  mean = sum(numbers) / len(numbers)\n",
        "  variance = sum((num - mean) ** 2 for num in numbers) / len(numbers)\n",
        "  return variance\n",
        "\n",
        "def calculate_standard_deviation(numbers):\n",
        "\n",
        "  variance = calculate_variance(numbers)\n",
        "  standard_deviation = variance ** 0.5\n",
        "  return standard_deviation\n",
        "\n",
        "print(calculate_variance(data1))\n",
        "print(calculate_standard_deviation(data1))"
      ],
      "metadata": {
        "id": "QmOTWfeH33wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iv) Implement a function to compute the interquartile range (IQR) of a list of values."
      ],
      "metadata": {
        "id": "Bc5pdhFYo77w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iqr(numbers):\n",
        "\n",
        "  if not numbers:\n",
        "    return \"List cannot be empty\"\n",
        "  if len(numbers) < 4:\n",
        "    return \"List must contain at least 4 elements\"\n",
        "\n",
        "\n",
        "  sorted_numbers = sorted(numbers)\n",
        "\n",
        "\n",
        "  q1 = sorted_numbers[int(len(sorted_numbers) / 4)]\n",
        "  q3 = sorted_numbers[int(3 * len(sorted_numbers) / 4)]\n",
        "\n",
        "\n",
        "  iqr = q3 - q1\n",
        "  return iqr\n",
        "calculate_iqr(data1)"
      ],
      "metadata": {
        "id": "i3eNK15O4Iu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(v) Build a program to calculate the coefficient of variation for a dataset."
      ],
      "metadata": {
        "id": "PtW6eWCKo75A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cv(numbers):\n",
        "\n",
        "  if not numbers:\n",
        "    return\"List cannot be empty\"\n",
        "  if any(num == 0 for num in numbers):\n",
        "    return\"List cannot contain zero values\"\n",
        "\n",
        "  mean = sum(numbers) / len(numbers)\n",
        "  standard_deviation = np.std(numbers)\n",
        "  cv = (standard_deviation / mean) * 100\n",
        "  return cv\n",
        "\n",
        "calculate_cv(data1)"
      ],
      "metadata": {
        "id": "_sqX3jSu4hEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(vi) Write a Python function to find the mean absolute deviation (MAD) of a list of numbers."
      ],
      "metadata": {
        "id": "UAOkPAE-o71w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mad(numbers):\n",
        "\n",
        "  if not numbers:\n",
        "    return \"List cannot be empty\"\n",
        "\n",
        "  median = np.median(numbers)\n",
        "\n",
        "  absolute_deviations = [abs(num - median) for num in numbers]\n",
        "\n",
        "  return sum(absolute_deviations) / len(numbers)\n",
        "\n",
        "calculate_mad(data1)\n"
      ],
      "metadata": {
        "id": "Cp8fxGKL4y5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(vii) Create a program to calculate the quartile deviation of a list of values."
      ],
      "metadata": {
        "id": "4xHn-irzo7iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_quartile_deviation(numbers):\n",
        "\n",
        "  if not numbers:\n",
        "    return \"List cannot be empty\"\n",
        "  if len(numbers) < 4:\n",
        "    return \"List must contain at least 4 elements\"\n",
        "\n",
        "  sorted_numbers = sorted(numbers)\n",
        "\n",
        "  q1 = sorted_numbers[int(len(sorted_numbers) / 4)]\n",
        "  q3 = sorted_numbers[int(3 * len(sorted_numbers) / 4)]\n",
        "\n",
        "  qd = (q3 - q1) / 2\n",
        "  return qd\n",
        "\n",
        "calculate_quartile_deviation(data1)"
      ],
      "metadata": {
        "id": "c0hIa25T5ix6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(viii) Implement a function to find the range-based coefficient of dispersion for a dataset."
      ],
      "metadata": {
        "id": "0lGsguZupOMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range_based_coefficient(numbers):\n",
        "  if not numbers:\n",
        "    return \"List cannot be empty\"\n",
        "\n",
        "  minimum = min(numbers)\n",
        "  maximum = max(numbers)\n",
        "\n",
        "  range_ = maximum - minimum\n",
        "\n",
        "  coefficient = range_ / (minimum + maximum)\n",
        "\n",
        "  return coefficient\n",
        "\n",
        "calculate_range_based_coefficient(data1)\n"
      ],
      "metadata": {
        "id": "mUk0Y1RQ5sT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Write a Python class representing a discrete random variable with methods to calculate its expected value and variance**"
      ],
      "metadata": {
        "id": "-SHKjms0perH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscreteRandomVariable:\n",
        "\n",
        "  def __init__(self, values, probabilities):\n",
        "\n",
        "    if len(values) != len(probabilities):\n",
        "      return\"Length of values and probabilities must be equal\"\n",
        "    if sum(probabilities) != 1:\n",
        "      return\"Sum of probabilities must be equal to 1\"\n",
        "\n",
        "    self.values = values\n",
        "    self.probabilities = probabilities\n",
        "\n",
        "  def expected_value(self):\n",
        "\n",
        "    expected_value = sum(value * probability for value, probability in zip(self.values, self.probabilities))\n",
        "    return expected_value\n",
        "\n",
        "  def variance(self):\n",
        "\n",
        "    mean = self.expected_value()\n",
        "    variance = sum((value - mean) ** 2 * probability for value, probability in zip(self.values, self.probabilities))\n",
        "    return variance\n",
        "\n",
        "values = [1, 2, 3, 4]\n",
        "probabilities = [0.2, 0.3, 0.4, 0.1]\n",
        "random_variable = DiscreteRandomVariable(values, probabilities)\n",
        "\n",
        "expected_value = random_variable.expected_value()\n",
        "variance = random_variable.variance()\n",
        "\n",
        "print(expected_value)"
      ],
      "metadata": {
        "id": "aRoE43fA6H5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Implement a program to simulate the rolling of a fair six-sided die and calculate the expected value and variance of the outcomes.**"
      ],
      "metadata": {
        "id": "m764ccNOpvNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def roll_die():\n",
        "\n",
        "  return random.randint(1, 6)\n",
        "\n",
        "def calculate_statistics(num_rolls):\n",
        "  expected_value = 3.5\n",
        "  variance = 0\n",
        "\n",
        "  for _ in range(num_rolls):\n",
        "    roll = roll_die()\n",
        "    variance += (roll - expected_value) ** 2\n",
        "\n",
        "  variance /= num_rolls\n",
        "\n",
        "  return expected_value, variance\n",
        "\n",
        "num_rolls = 1000\n",
        "expected_value, variance = calculate_statistics(num_rolls)\n",
        "print(f\"Expected value {num_rolls}, {expected_value}\")"
      ],
      "metadata": {
        "id": "W81btNalBp0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Create a Python function to generate random samples from a given probability distribution (e.g., binomial, Poisson) and calculate their mean and variance.**"
      ],
      "metadata": {
        "id": "YUEGKCvNp3jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def generate_samples_and_stats(distribution, n, *args):\n",
        "\n",
        "  if distribution == \"binomial\":\n",
        "    if len(args) != 1:\n",
        "      return\"Binomial distribution requires probability (p)\"\n",
        "    p = args[0]\n",
        "    samples = np.random.binomial(1, p, n)\n",
        "  elif distribution == \"poisson\":\n",
        "    if len(args) != 1:\n",
        "      return\"Poisson distribution requires lambda (lam)\"\n",
        "    lam = args[0]\n",
        "    samples = np.random.poisson(lam, n)\n",
        "  else:\n",
        "    return\"Invalid distribution specified\"\n",
        "\n",
        "  mean = np.mean(samples)\n",
        "  variance = np.var(samples)\n",
        "  return samples.tolist(), mean, variance\n",
        "\n",
        "# (binomial distribution)\n",
        "n = 1000\n",
        "p = 0.5\n",
        "samples, mean, variance = generate_samples_and_stats(\"binomial\", n, p)\n",
        "print(f\"Binomial distribution (n={n}, p={p}):\")\n",
        "print(f\"Sample: {samples[:10]}\")\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Variance: {variance}\")"
      ],
      "metadata": {
        "id": "OAuvXjRHCzJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Write a Python script to generate random numbers from a Gaussian (normal) distribution and compute the mean, variance, and standard deviation of the samples.**"
      ],
      "metadata": {
        "id": "6mZpmzMCp4nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "mean = 5\n",
        "std_dev = 2\n",
        "num_samples = 1000\n",
        "\n",
        "samples = np.random.normal(loc=mean, scale=std_dev, size=num_samples)\n",
        "\n",
        "\n",
        "sample_mean = np.mean(samples)\n",
        "sample_variance = np.var(samples)\n",
        "sample_std_dev = np.std(samples)\n",
        "\n",
        "\n",
        "print(f\"Number of samples generated: {num_samples}\")\n",
        "print(f\"Mean of the samples: {sample_mean}\")\n",
        "print(f\"Variance of the samples: {sample_variance}\")\n",
        "print(f\"Standard deviation of the samples: {sample_std_dev}\")"
      ],
      "metadata": {
        "id": "zijRhAc0Dayb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Use seaborn library to load `tips` dataset. Find the following from the dataset for the columns `total_bill` and `tip`:**"
      ],
      "metadata": {
        "id": "eFNVDkXLp4kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "data = sns.load_dataset(\"tips\")"
      ],
      "metadata": {
        "id": "I8GewynNJBFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(i) Write a Python function that calculates their skewness."
      ],
      "metadata": {
        "id": "V69kjz_Ep4g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_skewness(data):\n",
        "    numerical_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "    skewness = numerical_data.skew()\n",
        "    return skewness\n",
        "\n",
        "skewness = calculate_skewness(data)\n",
        "print(skewness)\n"
      ],
      "metadata": {
        "id": "V_F1-Sz9Ebp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(ii) Create a program that determines whether the columns exhibit positive skewness, negative skewness, or is approximately symmetric."
      ],
      "metadata": {
        "id": "Z9ps1t5sp4eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def skewness_description(skewness):\n",
        "    if skewness > 0:\n",
        "        return 'Positive skewness'\n",
        "    elif skewness < 0:\n",
        "        return 'Negative skewness'\n",
        "    else:\n",
        "        return 'Approximately symmetric'\n",
        "\n",
        "def analyze_skewness(data):\n",
        "    numerical_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "    skewness = numerical_data.skew()\n",
        "\n",
        "    skewness_analysis = {col: skewness_description(skw) for col, skw in skewness.items()}\n",
        "\n",
        "    return skewness_analysis\n",
        "\n",
        "\n",
        "skewness_analysis = analyze_skewness(data)\n",
        "for col, analysis in skewness_analysis.items():\n",
        "    print(f\"Column '{col}': {analysis}\")"
      ],
      "metadata": {
        "id": "boS0_g5dFCUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iii) Write a function that calculates the covariance between two columns."
      ],
      "metadata": {
        "id": "P3ciNLsUp4av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_covariance(data, col1, col2):\n",
        "\n",
        "    if col1 not in data.columns or col2 not in data.columns:\n",
        "        return\"One or both columns '{col1}' and '{col2}' do not exist in the DataFrame.\"\n",
        "\n",
        "    covariance = data[[col1, col2]].cov().iloc[0, 1]\n",
        "    return covariance\n",
        "\n",
        "data = sns.load_dataset(\"tips\")\n",
        "\n",
        "col1 = 'total_bill'\n",
        "col2 = 'tip'\n",
        "calculate_covariance(data, col1, col2)"
      ],
      "metadata": {
        "id": "NDvFZxeVFiyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(iv) Implement a Python program that calculates the Pearson correlation coefficient between two columns"
      ],
      "metadata": {
        "id": "M_oQADQsp4X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_pearson_correlation(data, col1, col2):\n",
        "\n",
        "    if col1 not in data.columns or col2 not in data.columns:\n",
        "        return\"One or both columns '{col1}' and '{col2}' do not exist in the DataFrame.\"\n",
        "\n",
        "    pearson_correlation = data[[col1, col2]].corr().iloc[0, 1]\n",
        "    return pearson_correlation\n",
        "\n",
        "\n",
        "col1 = 'total_bill'\n",
        "col2 = 'tip'\n",
        "calculate_pearson_correlation(data, col1, col2)"
      ],
      "metadata": {
        "id": "5F5lzwGyIJec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(v) Write a script to visualize the correlation between two specific columns in a Pandas DataFrame using scatter plots"
      ],
      "metadata": {
        "id": "5ASJRwbMp4Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = sns.load_dataset(\"tips\")\n",
        "\n",
        "x_column = 'total_bill'\n",
        "y_column = 'tip'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(data[x_column], data[y_column], color='blue', alpha=0.5)\n",
        "plt.title(f'Scatter plot of {x_column} vs {y_column}')\n",
        "plt.xlabel(x_column)\n",
        "plt.ylabel(y_column)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JuJTAg76Iqop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Write a Python function to calculate the probability density function (PDF) of a continuous random variable for a given normal distribution.**"
      ],
      "metadata": {
        "id": "GU3CqM4fp4Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_normal_pdf(mu, sigma):\n",
        "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
        "\n",
        "\n",
        "    pdf = norm.pdf(x, mu, sigma)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, pdf, 'b-', label=f'PDF (mu={mu}, sigma={sigma})')\n",
        "    plt.title('Normal Distribution PDF')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "mu = 0\n",
        "sigma = 1\n",
        "\n",
        "plot_normal_pdf(mu, sigma)\n"
      ],
      "metadata": {
        "id": "2UQZQJoHJw8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Create a program to calculate the cumulative distribution function (CDF) of exponential distribution.**"
      ],
      "metadata": {
        "id": "f7vpo-Xdp4OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import expon\n",
        "\n",
        "def plot_exponential_cdf(rate):\n",
        "    x = np.linspace(0, 5, 1000)\n",
        "\n",
        "    cdf = expon.cdf(x, scale=1/rate)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, cdf, 'b-', label=f'CDF (rate={rate})')\n",
        "    plt.title('Exponential Distribution CDF')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Cumulative Probability')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "rate = 0.5\n",
        "plot_exponential_cdf(rate)"
      ],
      "metadata": {
        "id": "JKIzlaJXKao0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Write a Python function to calculate the probability mass function (PMF) of Poisson distribution.**"
      ],
      "metadata": {
        "id": "nTamou5Yp4KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "def plot_poisson_pmf(mu, max_k):\n",
        "    k_values = np.arange(0, max_k + 1)\n",
        "\n",
        "    pmf = poisson.pmf(k_values, mu)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.stem(k_values, pmf, basefmt=\" \", use_line_collection=True)\n",
        "    plt.title(f'Poisson Distribution PMF (mu={mu})')\n",
        "    plt.xlabel('k')\n",
        "    plt.ylabel('Probability Mass')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "mu = 3\n",
        "max_k = 10\n",
        "\n",
        "plot_poisson_pmf(mu, max_k)"
      ],
      "metadata": {
        "id": "iI5GFOe2Kt0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. A company wants to test if a new website layout leads to a higher conversion rate (percentage of visitors who make a purchase). They collect data from the old and new layouts to compare.**\n",
        "\n",
        "To generate the data use the following command:\n",
        "\n",
        "python import numpy as np # 50 purchases out of 1000\n",
        "\n",
        "visitors old_layout = np.array([1] * 50 + [0] * 950) # 70 purchases out of 1000 visitors\n",
        "\n",
        "new_layout = np.array([1] * 70 + [0] * 930)\n",
        "\n",
        "Apply z-test to find which layout is successful"
      ],
      "metadata": {
        "id": "R5SAnTUsp4HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "old_layout = np.array([1] * 50 + [0] * 950)\n",
        "new_layout = np.array([1] * 70 + [0] * 930)\n",
        "\n",
        "p_old = np.mean(old_layout)\n",
        "p_new = np.mean(new_layout)\n",
        "\n",
        "\n",
        "count = np.array([np.sum(new_layout), np.sum(old_layout)])\n",
        "nobs = np.array([len(new_layout), len(old_layout)])\n",
        "\n",
        "z_score, p_value = proportions_ztest(count, nobs, alternative='larger')\n",
        "\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: The new layout leads to a significantly higher conversion rate.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no sufficient evidence that the new layout leads to a higher conversion rate.\")"
      ],
      "metadata": {
        "id": "7O2_H304LRA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. A tutoring service claims that its program improves students' exam scores. A sample of students who participated in the program was taken, and their scores before and after the program were recorded.**\n",
        "\n",
        " Use the below code to generate samples of respective arrays of marks:\n",
        "\n",
        "python before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
        "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
        "  \n",
        "Use z-test to find if the claims made by tutor are true or false"
      ],
      "metadata": {
        "id": "SHM3Ti7mrHWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
        "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
        "\n",
        "diff = after_program - before_program\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff, ddof=1)\n",
        "n = len(diff)\n",
        "se = std_diff / np.sqrt(n)\n",
        "\n",
        "z_score = mean_diff / se\n",
        "p_value = 2 * (1 - stats.norm.cdf(np.abs(z_score)))\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: The tutoring program significantly improves exam scores.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no sufficient evidence that the tutoring program improves exam scores.\")\n"
      ],
      "metadata": {
        "id": "7XSqwzymL5wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. A pharmaceutical company wants to determine if a new drug is effective in reducing blood pressure. They conduct a study and record blood pressure measurements before and after administering the drug.**\n",
        "\n",
        "Use the below code to generate samples of respective arrays of blood pressure:\n",
        "python before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
        "\n",
        "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
        "\n",
        "Implement z-test to find if the drug really works or not."
      ],
      "metadata": {
        "id": "I_5G9O8FrHSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
        "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
        "\n",
        "diff = after_drug - before_drug\n",
        "mean_diff = np.mean(diff)\n",
        "std_diff = np.std(diff, ddof=1)\n",
        "n = len(diff)\n",
        "\n",
        "se = std_diff / np.sqrt(n)\n",
        "\n",
        "\n",
        "z_score = mean_diff / se\n",
        "p_value = 2 * (1 - stats.norm.cdf(np.abs(z_score)))\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: The drug significantly reduces blood pressure.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: There is no sufficient evidence that the drug reduces blood pressure.\")\n"
      ],
      "metadata": {
        "id": "4aUq133dNJZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. A customer service department claims that their average response time is less than 5 minutes. A sample of recent customer interactions was taken, and the response times were recorded.**\n",
        "\n",
        "Implement the below code to generate the array of response time:\n",
        "\n",
        "python response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
        "\n",
        "Implement z-test to find the claims made by customer service department are tru or false."
      ],
      "metadata": {
        "id": "2-rr7Pd4rHPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
        "\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "mean_response_time = np.mean(response_times)\n",
        "std_dev = np.std(response_times)\n",
        "\n",
        "z_statistic = (mean_response_time - 5) / (std_dev / np.sqrt(len(response_times)))\n",
        "\n",
        "p_value = 2 * (1 - stats.norm.cdf(z_statistic))\n",
        "\n",
        "if p_value < alpha:\n",
        "\n",
        "  print(\"We reject the customer service department's claim that the average response time is less than 5 minutes\")\n",
        "else:\n",
        "  print(\"We fail to reject the customer service department's claim that the average response time is less than 5 minutes\")\n"
      ],
      "metadata": {
        "id": "gXzPQAT8ODGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. A company is testing two different website layouts to see which one leads to higher click-through rates. Write a Python function to perform an A/B test analysis, including calculating the t-statistic, degrees of freedom, and p-value.**\n",
        "\n",
        "Use the following data:\n",
        "\n",
        "python layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
        "\n",
        "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]"
      ],
      "metadata": {
        "id": "KplJglEerHL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def ab_test_analysis(layout_a_clicks, layout_b_clicks):\n",
        "\n",
        "  clicks_a = np.array(layout_a_clicks)\n",
        "  clicks_b = np.array(layout_b_clicks)\n",
        "\n",
        "  mean_a = np.mean(clicks_a)\n",
        "  mean_b = np.mean(clicks_b)\n",
        "  std_dev_a = np.std(clicks_a)\n",
        "  std_dev_b = np.std(clicks_b)\n",
        "\n",
        "  pooled_std_dev = np.sqrt(((len(clicks_a) - 1) * std_dev_a**2 + (len(clicks_b) - 1) * std_dev_b**2) / (len(clicks_a) + len(clicks_b) - 2))\n",
        "\n",
        "  df = len(clicks_a) + len(clicks_b) - 2\n",
        "\n",
        "  t_statistic = (mean_a - mean_b) / (pooled_std_dev * np.sqrt(1 / len(clicks_a) + 1 / len(clicks_b)))\n",
        "\n",
        "  p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "  return {\n",
        "      \"t_statistic\": t_statistic,\n",
        "      \"degrees_of_freedom\": df,\n",
        "      \"p_value\": p_value\n",
        "  }\n",
        "\n",
        "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
        "\n",
        "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]\n",
        "\n",
        "ab_test_analysis(layout_a_clicks, layout_b_clicks)"
      ],
      "metadata": {
        "id": "vmFK2eSJPJft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. A pharmaceutical company wants to determine if a new drug is more effective than an existing drug in reducing cholesterol levels. Create a program to analyze the clinical trial data and calculate the t- statistic and p-value for the treatment effect**\n",
        "\n",
        "Use the following data of cholestrol level:\n",
        "\n",
        "python existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
        "\n",
        "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]"
      ],
      "metadata": {
        "id": "ByElYnCAp4BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
        "\n",
        "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
        "\n",
        "t_statistic, p_value = stats.ttest_ind(existing_drug_levels, new_drug_levels, equal_var=False)\n",
        "\n",
        "if p_value < 0.05:\n",
        "  print(\"We reject the null hypothesis that there is no difference between the existing and new drug in reducing cholesterol levels. The new drug appears to be more effective (p-value =\", p_value, \").\")\n",
        "else:\n",
        "  print(\"We fail to reject the null hypothesis. There is not enough evidence to conclude that the new drug is more effective in reducing cholesterol levels (p-value =\", p_value, \").\")\n"
      ],
      "metadata": {
        "id": "nsvPUdE6P5Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. A school district introduces an educational intervention program to improve math scores. Write a Python function to analyze pre- and post-intervention test scores, calculating the t-statistic and p-value to determine if the intervention had a significant impact.**\n",
        "\n",
        "Use the following data of test score:\n",
        "\n",
        "python pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
        "\n",
        "post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]"
      ],
      "metadata": {
        "id": "NWTP9Ejqp3uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def analyze_intervention(pre_intervention_scores, post_intervention_scores):\n",
        "\n",
        "  if len(pre_intervention_scores) != len(post_intervention_scores):\n",
        "    raise ValueError(\"Unequal data lengths for pre- and post-intervention scores.\")\n",
        "\n",
        "  t_statistic, p_value = stats.ttest_rel(pre_intervention_scores, post_intervention_scores)\n",
        "\n",
        "  return {\n",
        "      \"t_statistic\": t_statistic,\n",
        "      \"degrees_of_freedom\": len(pre_intervention_scores) - 1,\n",
        "      \"p_value\": p_value\n",
        "  }\n",
        "\n",
        "pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
        "post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
        "\n",
        "results = analyze_intervention(pre_intervention_scores, post_intervention_scores)\n",
        "\n",
        "if results[\"p_value\"] < 0.05:\n",
        "  print(\"The intervention appears to have a significant positive impact on math scores (p-value =\", results[\"p_value\"], \").\")\n",
        "else:\n",
        "  print(\"There is not enough evidence to conclude that the intervention has a significant impact on math scores (p-value =\", results[\"p_value\"], \").\")\n"
      ],
      "metadata": {
        "id": "YXLAVsNxQMfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. An HR department wants to investigate if there's a gender-based salary gap within the company. Develop a program to analyze salary data, calculate the t-statistic, and determine if there's a statistically significant difference between the average salaries of male and female employees.**\n",
        "\n",
        "Use the below code to generate synthetic data:\n",
        "\n",
        "python\n",
        "\n",
        "Generate synthetic salary data for male and female employees\n",
        "\n",
        "np.random.seed(0)   For reproducibility\n",
        "\n",
        "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
        "\n",
        "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)"
      ],
      "metadata": {
        "id": "hTNZhfi-tX3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "np.random.seed(0)\n",
        "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
        "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "t_statistic, p_value = stats.ttest_ind(male_salaries, female_salaries, equal_var=False)\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"We reject the null hypothesis that there is no gender-based salary gap. \")\n",
        "else:\n",
        "  print(\"We fail to reject the null hypothesis.\")"
      ],
      "metadata": {
        "id": "POklUd-MQhZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. A manufacturer produces two different versions of a product and wants to compare their quality scores. Create a Python function to analyze quality assessment data, calculate the t-statistic, and decide whether there's a significant difference in quality between the two versions.**\n",
        "\n",
        "Use the following data:\n",
        "\n",
        "python version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
        "\n",
        "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]"
      ],
      "metadata": {
        "id": "GeoabPWLt25A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "def compare_versions(version1_scores, version2_scores):\n",
        "\n",
        "\n",
        "  if len(version1_scores) != len(version2_scores):\n",
        "    return\"Unequal data lengths for version 1 and 2 scores.\"\n",
        "\n",
        "  t_statistic, p_value = stats.ttest_ind(version1_scores, version2_scores, equal_var=False)\n",
        "\n",
        "\n",
        "  return {\n",
        "      \"t_statistic\": t_statistic,\n",
        "      \"degrees_of_freedom\": len(version1_scores) - 1,\n",
        "      \"p_value\": p_value\n",
        "  }\n",
        "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
        "\n",
        "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]\n",
        "\n",
        "results = compare_versions(version1_scores, version2_scores)\n",
        "\n",
        "if results[\"p_value\"] < 0.05:\n",
        "  print(\"The data suggests a statistically significant difference in quality between the two versions \")\n",
        "else:\n",
        "  print(\"There is not enough evidence to conclude a statistically significant difference in quality based on this data (p-value =\", results[\"p_value\"], \").\")\n"
      ],
      "metadata": {
        "id": "XkOG9jT0QztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. A restaurant chain collects customer satisfaction scores for two different branches. Write a program to analyze the scores, calculate the t-statistic, and determine if there's a statistically significant difference in customer satisfaction between the branches.\n",
        "Use the below data of scores:**\n",
        "\n",
        "python\n",
        "\n",
        "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
        "\n",
        " branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]"
      ],
      "metadata": {
        "id": "fG9vICMKuBeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
        "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]\n",
        "\n",
        "\n",
        "alpha = 0.05\n",
        "t_statistic, p_value = stats.ttest_ind(branch_a_scores, branch_b_scores, equal_var=False)\n",
        "\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"We reject the null hypothesis that there is no difference in customer satisfaction between branches. \")\n",
        "else:\n",
        "\n",
        "  print(\"There is not enough evidence to conclude a statistically significant difference in customer satisfaction based on this data (p-value =\", p_value, \").\")\n",
        "\n",
        "if p_value < alpha:\n",
        "  if np.mean(branch_a_scores) > np.mean(branch_b_scores):\n",
        "    print(\"Branch A appears to have higher customer satisfaction on average.\")\n",
        "  else:\n",
        "    print(\"Branch B appears to have higher customer satisfaction on average.\")\n",
        "else:\n",
        "  print(\"Further investigation might be needed to understand customer satisfaction at each branch.\")\n"
      ],
      "metadata": {
        "id": "CA1XCHSFRRMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. A political analyst wants to determine if there is a significant association between age groups and voter preferences (Candidate A or Candidate B). They collect data from a sample of 500 voters and classify them into different age groups and candidate preferences. Perform a Chi-Square test to determine if there is a significant association between age groups and voter preferences. Use the below code to generate data:**\n",
        "\n",
        "python\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "age_groups = np.random.choice(['18-30', '31-50', '51+', '51+'], size=30)\n",
        "\n",
        "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=30)\n"
      ],
      "metadata": {
        "id": "FA2OhCASuMpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "age_groups = np.random.choice(['18-30', '31-50', '51+', '51+'], size=500)\n",
        "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)\n",
        "\n",
        "contingency_table = np.zeros((len(np.unique(age_groups)), len(np.unique(voter_preferences))))\n",
        "\n",
        "for i, age_group in enumerate(np.unique(age_groups)):\n",
        "    for j, preference in enumerate(np.unique(voter_preferences)):\n",
        "        contingency_table[i, j] = np.sum((age_groups == age_group) & (voter_preferences == preference))\n",
        "\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-Square Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)\n"
      ],
      "metadata": {
        "id": "k4trOB5RRuRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. A company conducted a customer satisfaction survey to determine if there is a significant relationship between product satisfaction levels (Satisfied, Neutral, Dissatisfied) and the region where customers are located (East, West, North, South). The survey data is summarized in a contingency table. Conduct a ChiSquare test to determine if there is a significant relationship between product satisfaction levels and customer regions.**\n",
        "\n",
        "Sample data:\n",
        "\n",
        "Python\n",
        "\n",
        "Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
        "\n",
        "data = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])"
      ],
      "metadata": {
        "id": "yWNdzwQ6ugMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "data = np.array([[50, 30, 40, 20],\n",
        "                 [30, 40, 30, 50],\n",
        "                 [20, 30, 40, 30]])\n",
        "\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(f\"Chi-Square Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "rdm-pNd7Siyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. A company implemented an employee training program to improve job performance (Effective, Neutral, Ineffective). After the training, they collected data from a sample of employees and classified them based on their job performance before and after the training. Perform a Chi-Square test to determine if there is a significant difference between job performance levels before and after the training.**\n",
        "\n",
        "Sample data:\n",
        "\n",
        "Python\n",
        "\n",
        "\n",
        "Job performance levels before (rows) and after (columns) training\n",
        "\n",
        "data = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]]) ```"
      ],
      "metadata": {
        "id": "oODdfy3zu79A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "data = np.array([[50, 30, 20],\n",
        "                 [30, 40, 30],\n",
        "                 [20, 30, 40]])\n",
        "\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "\n",
        "print(f\"Chi-Square Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "HAqQTNT5TYR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. A company produces three different versions of a product: Standard, Premium, and Deluxe. The company wants to determine if there is a significant difference in customer satisfaction scores among the three product versions. They conducted a survey and collected customer satisfaction scores for each version from a random sample of customers. Perform an ANOVA test to determine if there is a significant difference in customer satisfaction scores.**\n",
        "\n",
        "Use the following data:\n",
        "\n",
        "Python\n",
        "\n",
        "Sample data: Customer satisfaction scores for each product version\n",
        "\n",
        "standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
        "\n",
        "premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
        "\n",
        "deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]"
      ],
      "metadata": {
        "id": "PX84eL4xvROB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
        "premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
        "deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]\n",
        "\n",
        "f_statistic, p_value = f_oneway(standard_scores, premium_scores, deluxe_scores)\n",
        "\n",
        "\n",
        "print(f\"One-way ANOVA\")\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis\")\n"
      ],
      "metadata": {
        "id": "Q1zLC0AjTfq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}